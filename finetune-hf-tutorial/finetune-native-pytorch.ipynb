{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db21b62-22a9-46e3-9bb6-cf1a62614c71",
   "metadata": {},
   "source": [
    "# Finetune (training) Hands-on\n",
    "\n",
    "次の内容の再現確認。 <https://huggingface.co/docs/transformers/ja/training#train-in-native-pytorch> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0303b0ef-5b85-4252-a4e0-8eee8a6801b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded224a-cf92-4a5d-9076-598f04085f85",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1255cac-219f-4872-86bd-e49eea92937a",
   "metadata": {},
   "source": [
    "データセットを読み込む。データセットは [YelpReviewFull](https://huggingface.co/datasets/Yelp/yelp_review_full) でローカルビジネスのレビューとその点数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b76a2f-43ce-49d1-83de-628716412a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29d71c-f41e-4282-88b5-ce0874761b09",
   "metadata": {},
   "source": [
    "トークナイザ(BERTより)を準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de2e191-356b-4ca7-b009-b05f3ab36cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae24d99-c847-4849-9be7-e9403afbe30c",
   "metadata": {},
   "source": [
    "データセットをあらかじめトークナイズしちゃう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0011f5-2fff-4efc-8218-05d8c53dfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875831b-c590-41b2-b796-a1e95750dde0",
   "metadata": {},
   "source": [
    "モデルが受け付けられるように、`text`列を削除し、`label`列を`labels`に変更する。  \n",
    "データセットの形式をPyTorchテンソルに変更する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17346a80-6659-4a54-bce5-a57456a04a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a0c8f-5ffb-4648-beed-264a291fea72",
   "metadata": {},
   "source": [
    "実行時間を短くするために、サブセットで学習&評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcc47ef-411e-41ba-98b8-68da4579ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa839bf6-52f6-42a8-96d5-ac004ce3f2e5",
   "metadata": {},
   "source": [
    "## Prepare DataLoader and\n",
    "\n",
    "10個を1バッチとして学習・検証する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9652a148-5619-4a2f-a60b-95a3bcec196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=batch_size)\n",
    "eval_dataloader = DataLoader(small_eval_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44ca600-3cb6-4e92-af3c-995a30d03a83",
   "metadata": {},
   "source": [
    "必要なラベル数を指定してモデルをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd1dca5-03f2-4fde-b850-8ca4fd84555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb87270-1072-495b-bb8c-ad00948c6f3c",
   "metadata": {},
   "source": [
    "## Optimizer and Learning rate schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da20b506-6868-485c-a611-b3832c0f0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe2850-7d71-4c66-b05e-c9a9643387b1",
   "metadata": {},
   "source": [
    "デフォルトのスケジューラーを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632b4669-7107-4efa-8ac1-568e8766a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c50b23-7563-4da4-bd7c-d1aa5950b944",
   "metadata": {},
   "source": [
    "GPU(CUDA)が利用できるならば、モデルをGPUにロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25d0c0db-56d3-47c1-8d36-ba7b3bfb5363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9e9f724-dd2a-45ca-aaa1-023a01769faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight                                           torch.Size([28996, 768])       torch.float32 True\n",
      "bert.embeddings.position_embeddings.weight                                       torch.Size([512, 768])         torch.float32 True\n",
      "bert.embeddings.token_type_embeddings.weight                                     torch.Size([2, 768])           torch.float32 True\n",
      "bert.embeddings.LayerNorm.weight                                                 torch.Size([768])              torch.float32 True\n",
      "bert.embeddings.LayerNorm.bias                                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.0.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.0.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.0.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.0.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.0.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.1.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.1.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.1.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.1.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.1.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.1.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.2.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.2.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.2.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.2.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.2.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.2.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.3.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.3.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.3.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.3.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.3.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.3.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.4.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.4.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.4.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.4.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.4.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.4.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.5.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.5.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.5.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.5.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.5.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.5.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.6.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.6.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.6.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.6.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.6.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.6.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.7.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.7.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.7.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.7.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.7.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.7.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.8.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.8.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.8.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.8.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.8.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.8.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.query.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.query.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.key.weight                                   torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.key.bias                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.value.weight                                 torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.9.attention.self.value.bias                                   torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.output.dense.weight                               torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.9.attention.output.dense.bias                                 torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias                             torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.intermediate.dense.weight                                   torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.9.intermediate.dense.bias                                     torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.9.output.dense.weight                                         torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.9.output.dense.bias                                           torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.output.LayerNorm.weight                                     torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.9.output.LayerNorm.bias                                       torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.query.weight                                torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.query.bias                                  torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.key.weight                                  torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.key.bias                                    torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.value.weight                                torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.10.attention.self.value.bias                                  torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.output.dense.weight                              torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.10.attention.output.dense.bias                                torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight                          torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias                            torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.intermediate.dense.weight                                  torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.10.intermediate.dense.bias                                    torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.10.output.dense.weight                                        torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.10.output.dense.bias                                          torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.output.LayerNorm.weight                                    torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.10.output.LayerNorm.bias                                      torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.query.weight                                torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.query.bias                                  torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.key.weight                                  torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.key.bias                                    torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.value.weight                                torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.11.attention.self.value.bias                                  torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.output.dense.weight                              torch.Size([768, 768])         torch.float32 True\n",
      "bert.encoder.layer.11.attention.output.dense.bias                                torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight                          torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias                            torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.intermediate.dense.weight                                  torch.Size([3072, 768])        torch.float32 True\n",
      "bert.encoder.layer.11.intermediate.dense.bias                                    torch.Size([3072])             torch.float32 True\n",
      "bert.encoder.layer.11.output.dense.weight                                        torch.Size([768, 3072])        torch.float32 True\n",
      "bert.encoder.layer.11.output.dense.bias                                          torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.output.LayerNorm.weight                                    torch.Size([768])              torch.float32 True\n",
      "bert.encoder.layer.11.output.LayerNorm.bias                                      torch.Size([768])              torch.float32 True\n",
      "bert.pooler.dense.weight                                                         torch.Size([768, 768])         torch.float32 True\n",
      "bert.pooler.dense.bias                                                           torch.Size([768])              torch.float32 True\n",
      "classifier.weight                                                                torch.Size([5, 768])           torch.float32 True\n",
      "classifier.bias                                                                  torch.Size([5])                torch.float32 True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:80s} {str(param.shape):30s} {param.dtype} {param.is_cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a30ca1-584f-4df6-8583-d675afc3db7a",
   "metadata": {},
   "source": [
    "## Training Loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b0ce6-3834-4955-9139-d04ecbd45f97",
   "metadata": {},
   "source": [
    "メトリックスの計算と表示を行う関数を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef5e19fd-e89f-487f-a5c0-f1a9181a282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def compute_metrics(epoch):\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "    \n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "    print(f\"#{epoch}  {metric.compute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae20e1f-ebda-4b5e-a3a5-7a30e7afec61",
   "metadata": {},
   "source": [
    "学習の流れ\n",
    "1. データローダーから 1 バッチを読み込む\n",
    "2. モデルに1バッチを流し込み、結果 `outputs` を得る。おそらく `.loss` には教師データと計算結果の差分が入ってる\n",
    "3. `loss.backward()` で学習を実施\n",
    "4. `optimizer` と `lr_schedular` を更新 (学習の収束≒学習率のダンピングを狙ってるんだと思うけど、実際にはどういう効果があるんだろう?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466f0754-28d9-4425-a106-4ad05a06d907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2a5fca87504d9c9eae45c569290d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0  {'accuracy': 0.165}\n",
      "#1  {'accuracy': 0.434}\n",
      "#2  {'accuracy': 0.58}\n",
      "#3  {'accuracy': 0.596}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# 学習前のメトリックスを計算・表示\n",
    "compute_metrics(0)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    compute_metrics(epoch+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
